{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis of zero shot approach on fine-tuned and untrained MISTRAL-7B model\n",
        "**Author:** Sai Hemanth Kilaru\n",
        "\n",
        "In this project, I have done my observation  on checking the zero shot setup on the fine-tuned model and the base_model and check whether there is any difference on the performance on the test samples: **BERT score** and **ROGUE**.\n",
        "### Data domain: Medical"
      ],
      "metadata": {
        "id": "2LxVYqr_OqJM"
      },
      "id": "2LxVYqr_OqJM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "This was a many days hardwork;I knew a few concepts and a few i have learned especially for this project.\n",
        "\n",
        "**Let's get started:**\n",
        "1. To run this project: Please run it in Google Collab(T4 GPU);otherwise it will throw an error.\n",
        "2. I have added my sources from where i have referred a few codelines.\n",
        "3. Special thanks to my professor \"Bulut\" for helping me out by scaling the idea of my project ."
      ],
      "metadata": {
        "id": "X2ClfbNxQogo"
      },
      "id": "X2ClfbNxQogo"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "siAoY5L1VUYR"
      },
      "id": "siAoY5L1VUYR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Source: There is one major source i have referref to : https://medium.com/@anicomanesh/unleashing-the-power-of-mistral-7b-efficient-fine-tuning-for-medical-qa-fb3afaaa36e4                    .From this blog , I have finalised my llm model and i have referred the few portion of the  training part and few changes i have gone through the official documentation of the libraries and few troubleshooting for the errors is done by me and stack overflow ."
      ],
      "metadata": {
        "id": "_LBq64JOUY__"
      },
      "id": "_LBq64JOUY__"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing the Necessary Packages\n",
        "\n",
        "(It has to be run in a T4 GPU,please run this command to install necessary libraries)"
      ],
      "metadata": {
        "id": "LVJ8kak9R4GJ"
      },
      "id": "LVJ8kak9R4GJ"
    },
    {
      "cell_type": "code",
      "source": [
        "#Installation stuff\n",
        "%%capture\n",
        "%pip install -U transformers #for loading and fine-tuning transformer models\n",
        "%pip install -U datasets #To load my hugging face dataset from this\n",
        "%pip install -U trl#training transformer models with Reinforcement Learning\n",
        "%pip install -U bitsandbytes #model quantization(memory efficient)\n",
        "%pip install -U wandb #experiment tracking(In blog)\n",
        "%pip install -U accelerate #efficient training\n",
        "%pip install -U peft #parameter-efficient fine-tuning"
      ],
      "metadata": {
        "id": "Vs08DhiMOfxk"
      },
      "id": "Vs08DhiMOfxk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing the Libraries"
      ],
      "metadata": {
        "id": "aFm46M0QSURj"
      },
      "id": "aFm46M0QSURj"
    },
    {
      "cell_type": "code",
      "source": [
        "#setup:loading the models from the libraries\n",
        "from transformers import AutoModelForCausalLM,AutoTokenizer,BitsAndBytesConfig,HfArgumentParser,TrainingArguments,pipeline,logging\n",
        "from peft import LoraConfig,PeftModel,prepare_model_for_kbit_training,get_peft_model\n",
        "import os, torch, wandb#torch-for model operations on GPU\n",
        "from datasets import load_dataset\n",
        "from trl import SFTTrainer #fine-tuning\n",
        "from trl import setup_chat_format"
      ],
      "metadata": {
        "id": "K7P3IMR1a-tu"
      },
      "id": "K7P3IMR1a-tu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Authentication step\n",
        "This is crucial,we need to connect to the huggingface through it's API key in order to use its modesls;in the same way we need to connect to wandb to track training."
      ],
      "metadata": {
        "id": "dkij_-VzWcbc"
      },
      "id": "dkij_-VzWcbc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "639b2df7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-12T20:53:52.323803Z",
          "iopub.status.busy": "2024-10-12T20:53:52.323228Z",
          "iopub.status.idle": "2024-10-12T20:53:57.763441Z",
          "shell.execute_reply": "2024-10-12T20:53:57.762513Z"
        },
        "papermill": {
          "duration": 5.451886,
          "end_time": "2024-10-12T20:53:57.765772",
          "exception": false,
          "start_time": "2024-10-12T20:53:52.313886",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "639b2df7",
        "outputId": "7ab86acb-5226-446d-82bf-84cfc6337be8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: fineGrained).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhemu77\u001b[0m (\u001b[33mhemu77-university-of-arizona\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241102_222709-vtts4gkx</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/hemu77-university-of-arizona/Fine-tune%20Mistral%207B%20Instruct%20on%20Medical%20Dataset/runs/vtts4gkx' target=\"_blank\">silver-serenity-18</a></strong> to <a href='https://wandb.ai/hemu77-university-of-arizona/Fine-tune%20Mistral%207B%20Instruct%20on%20Medical%20Dataset' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/hemu77-university-of-arizona/Fine-tune%20Mistral%207B%20Instruct%20on%20Medical%20Dataset' target=\"_blank\">https://wandb.ai/hemu77-university-of-arizona/Fine-tune%20Mistral%207B%20Instruct%20on%20Medical%20Dataset</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/hemu77-university-of-arizona/Fine-tune%20Mistral%207B%20Instruct%20on%20Medical%20Dataset/runs/vtts4gkx' target=\"_blank\">https://wandb.ai/hemu77-university-of-arizona/Fine-tune%20Mistral%207B%20Instruct%20on%20Medical%20Dataset/runs/vtts4gkx</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "from huggingface_hub import login\n",
        "import wandb\n",
        "\n",
        "# we declare a variable for the storage of tokens(I am keeping the tokens public cuz my professor has to run that)\n",
        "hf_token = \"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\"  #  Hugging Face API token\n",
        "wb_token = \"cba0c643dcc54c8894fb596bce7311ea2dc00c57\"  #  Weights & Biases API token\n",
        "\n",
        "# login to Hugging Face\n",
        "login(token=hf_token)\n",
        "\n",
        "# login to Weights & Biases\n",
        "wandb.login(key=wb_token)\n",
        "\n",
        "# initializing a wandb run, to track the training .\n",
        "run = wandb.init(\n",
        "    project='Fine-tune Mistral 7B Instruct on Medical Dataset',#name\n",
        "    job_type=\"training\",\n",
        "    anonymous=\"allow\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7462a30f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-12T20:53:57.786553Z",
          "iopub.status.busy": "2024-10-12T20:53:57.786226Z",
          "iopub.status.idle": "2024-10-12T20:53:57.790484Z",
          "shell.execute_reply": "2024-10-12T20:53:57.789605Z"
        },
        "papermill": {
          "duration": 0.016805,
          "end_time": "2024-10-12T20:53:57.792459",
          "exception": false,
          "start_time": "2024-10-12T20:53:57.775654",
          "status": "completed"
        },
        "tags": [],
        "id": "7462a30f"
      },
      "outputs": [],
      "source": [
        "#Decaration of models\n",
        "base_model = \"mistralai/Mistral-7B-Instruct-v0.1\"         #basemodel->directly accessing it requires approval,approve it and then access if not\n",
        "dataset_name = \"ruslanmv/ai-medical-chatbot\"\n",
        "new_model = \"hemu's chat-doctor\"           #o/p model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c369900",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-12T20:53:57.813472Z",
          "iopub.status.busy": "2024-10-12T20:53:57.812667Z",
          "iopub.status.idle": "2024-10-12T20:53:57.816733Z",
          "shell.execute_reply": "2024-10-12T20:53:57.815890Z"
        },
        "papermill": {
          "duration": 0.016521,
          "end_time": "2024-10-12T20:53:57.818704",
          "exception": false,
          "start_time": "2024-10-12T20:53:57.802183",
          "status": "completed"
        },
        "tags": [],
        "id": "7c369900"
      },
      "outputs": [],
      "source": [
        "#configuring the data type and attention method for for model efficiency\n",
        "torch_dtype = torch.float16 #16-bit floating-point for efficiency\n",
        "attn_implementation = \"eager\" #to reduce memory usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "816d138e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-12T20:53:57.840116Z",
          "iopub.status.busy": "2024-10-12T20:53:57.839651Z",
          "iopub.status.idle": "2024-10-12T20:56:04.179227Z",
          "shell.execute_reply": "2024-10-12T20:56:04.178143Z"
        },
        "papermill": {
          "duration": 126.352916,
          "end_time": "2024-10-12T20:56:04.181599",
          "exception": false,
          "start_time": "2024-10-12T20:53:57.828683",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "2452632335924d479f7d94c01ae3c2d6",
            "ebb528d60c194d1f8444e58c78559c6c",
            "542b6c5e8d794f85b61f0f8c98a74c63",
            "9060eb9f3df94e1a9b368dcdc6391044",
            "6915c7b31f7141739651b31d3a474f93",
            "deb8db8a5a864057ad35931c8f113096",
            "34905186e8f34f10a9e6ecced5d46472",
            "5f931ee02737494089a20241b4c88fcc",
            "88cac15e6a734fdc9ef6afd5792900ef",
            "e98ee422e83f4e2fa9794f5cdd056c3a",
            "c2b1af3ecdde4c62877372e0d48d13f1"
          ]
        },
        "id": "816d138e",
        "outputId": "86ec5523-df47-4c46-ab33-f19251f7da2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2452632335924d479f7d94c01ae3c2d6"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#INSPIRED FROM THE SOURCE BLOG MENTIONED ABOVE (https://medium.com/@anicomanesh/unleashing-the-power-of-mistral-7b-efficient-fine-tuning-for-medical-qa-fb3afaaa36e4)\n",
        "# QLoRA config\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,        #load the model with 4-bit precision, reducing memory usage.\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch_dtype,\n",
        "    bnb_4bit_use_double_quant=True #To improve the efficiency,we set the double quantization\n",
        ")\n",
        "\n",
        "# Loading base model with the specified settings, placing it on the available device\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    attn_implementation=attn_implementation\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6a31a47",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-12T20:56:04.204122Z",
          "iopub.status.busy": "2024-10-12T20:56:04.203391Z",
          "iopub.status.idle": "2024-10-12T20:56:04.356001Z",
          "shell.execute_reply": "2024-10-12T20:56:04.355136Z"
        },
        "papermill": {
          "duration": 0.166577,
          "end_time": "2024-10-12T20:56:04.358591",
          "exception": false,
          "start_time": "2024-10-12T20:56:04.192014",
          "status": "completed"
        },
        "tags": [],
        "id": "c6a31a47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3af9e8a6-668c-46d7-8881-66883b4c780e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
            "The new lm_head weights will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
          ]
        }
      ],
      "source": [
        "#INSPIRED FROM THE SOURCE BLOG MENTIONED ABOVE (https://medium.com/@anicomanesh/unleashing-the-power-of-mistral-7b-efficient-fine-tuning-for-medical-qa-fb3afaaa36e4)\n",
        "# Loading the  tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
        "tokenizer.padding_side = 'right' #Padding applied to the right of sequences\n",
        "# Set pre-set chat_template to None to avoid conflicts;This i have figured it on my own through documentation(Error analysis)\n",
        "tokenizer.chat_template = None\n",
        "# Apply the chat format setup\n",
        "model, tokenizer = setup_chat_format(model, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "090e97a0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-12T20:56:04.379916Z",
          "iopub.status.busy": "2024-10-12T20:56:04.379596Z",
          "iopub.status.idle": "2024-10-12T20:56:05.166786Z",
          "shell.execute_reply": "2024-10-12T20:56:05.165767Z"
        },
        "papermill": {
          "duration": 0.800436,
          "end_time": "2024-10-12T20:56:05.169107",
          "exception": false,
          "start_time": "2024-10-12T20:56:04.368671",
          "status": "completed"
        },
        "tags": [],
        "id": "090e97a0"
      },
      "outputs": [],
      "source": [
        "#READ THE DOCUMENT AND ARRANGED IT IN THE BEST WAY(IN THE SOURCE MENTIONED ABOVE)\n",
        "# Loading and  configuring LoRA for efficient fine-tuning(There are the best parameters so far;so i have gone with them )\n",
        "peft_config = LoraConfig(\n",
        "    r=16, #low-rank matrix dimension\n",
        "    lora_alpha=32, #Scaling factor\n",
        "    lora_dropout=0.05, #dropout(regularization)\n",
        "    bias=\"none\", #no bias\n",
        "    task_type=\"CAUSAL_LM\", #causal language modeling\n",
        "    target_modules=['up_proj', 'down_proj', 'gate_proj', 'k_proj', 'q_proj', 'v_proj', 'o_proj'] #layers to apply the LoRA on\n",
        ")\n",
        "model = get_peft_model(model, peft_config)  #applying the config to the model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing the Data"
      ],
      "metadata": {
        "id": "J09CyBBsO5MA"
      },
      "id": "J09CyBBsO5MA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50824c17",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-12T20:56:05.190265Z",
          "iopub.status.busy": "2024-10-12T20:56:05.189955Z",
          "iopub.status.idle": "2024-10-12T20:56:09.184298Z",
          "shell.execute_reply": "2024-10-12T20:56:09.183194Z"
        },
        "papermill": {
          "duration": 4.007495,
          "end_time": "2024-10-12T20:56:09.186780",
          "exception": false,
          "start_time": "2024-10-12T20:56:05.179285",
          "status": "completed"
        },
        "tags": [],
        "id": "50824c17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "outputId": "cf12f7d0-0347-42a6-9331-472303333589"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<|im_start|>user\\nHello doctor, I am 28 years old. From the past two weeks, there is a slight pain in my right ear. I tried Clear Wax ear drops and normal ear drops then there is a relief for a certain period then again mild pain is coming the next day. When I wake up in the morning there is a very slight headache kind on the right side and some sort of discomfort in my right ear. There is not severe pain but certainly, there is some sort of mild pain. I also noticed whenever I tried using earbuds in my left ear to clean then I am getting cough as if some sort of itchiness sensation in the ear is causing immediate cough in the throat and normal again after I take earbud out. I want to know whether I should consult ENT specialist immediately or if there are any ear drops in particular to use before I go to ENT doctor.<|im_end|>\\n<|im_start|>assistant\\nHello. The cough which occurs during ear cleaning is due to stimulus to your auricular branch of the vagus nerve, which is normal. Now coming to your problem, many times mild pain occurs due to impacted wax or ETD (eustachian tube dysfunction). Both cases it is advisable to consult an ENT surgeon for the proper examination of the ear. Till then, continue the ear drop, do Valsalva 30 to 40 times a day. Never try to clean the ear yourself as it can cause injury to your ear.<|im_end|>\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "#Importing the dataset,randomly shuffles it with a seed for consistency, selecting a subset of 500 samples for faster processing.\n",
        "dataset = load_dataset(dataset_name, split=\"all\")\n",
        "# writing a function for removing the uninformative responses\n",
        "def is_uninformative(response):\n",
        "    if \"I don't know\" in response or \"consult a doctor\" in response:\n",
        "        return True\n",
        "    return False\n",
        "# Filter out uninformative doctor responses from the dataset\n",
        "dataset = dataset.filter(lambda x: not is_uninformative(x['Doctor']))\n",
        "#Now,we take the 500 good samples from that(As there is no specific perfect way to select the best 500 samples;I have chosen this way)\n",
        "\n",
        "dataset = dataset.shuffle(seed=65).select(range(500)) # Only use 500 in order to prevent the crashing of GPU(In collab)\n",
        "\n",
        "#format each data row into a user-assistant template ;which is suitable for chatbot responses.\n",
        "#INSPIRED FROM THE SOURCE BLOG MENTIONED ABOVE (https://medium.com/@anicomanesh/unleashing-the-power-of-mistral-7b-efficient-fine-tuning-for-medical-qa-fb3afaaa36e4)\n",
        "def format_chat_template(row):\n",
        "    row_json = [{\"role\": \"user\", \"content\": row[\"Patient\"]},\n",
        "               {\"role\": \"assistant\", \"content\": row[\"Doctor\"]}]\n",
        "    row[\"text\"] = tokenizer.apply_chat_template(row_json, tokenize=False)\n",
        "    return row\n",
        "#applying the formatting function to the entire dataset\n",
        "dataset = dataset.map(\n",
        "    format_chat_template,\n",
        "    num_proc=4,\n",
        ")\n",
        "\n",
        "dataset['text'][3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46647e8c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-12T20:56:09.210693Z",
          "iopub.status.busy": "2024-10-12T20:56:09.210390Z",
          "iopub.status.idle": "2024-10-12T20:56:09.223986Z",
          "shell.execute_reply": "2024-10-12T20:56:09.223239Z"
        },
        "papermill": {
          "duration": 0.027826,
          "end_time": "2024-10-12T20:56:09.225847",
          "exception": false,
          "start_time": "2024-10-12T20:56:09.198021",
          "status": "completed"
        },
        "tags": [],
        "id": "46647e8c"
      },
      "outputs": [],
      "source": [
        "#splitting the dataset\n",
        "dataset = dataset.train_test_split(test_size=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "144fb03f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-12T20:56:09.248736Z",
          "iopub.status.busy": "2024-10-12T20:56:09.248395Z",
          "iopub.status.idle": "2024-10-12T20:56:09.280123Z",
          "shell.execute_reply": "2024-10-12T20:56:09.278939Z"
        },
        "papermill": {
          "duration": 0.045806,
          "end_time": "2024-10-12T20:56:09.282163",
          "exception": false,
          "start_time": "2024-10-12T20:56:09.236357",
          "status": "completed"
        },
        "tags": [],
        "id": "144fb03f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1ae2936-89fe-44fd-eff2-fb7094e29d2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#TAKEN FROM THE SOURCE BLOG MENTIONED ABOVE (https://medium.com/@anicomanesh/unleashing-the-power-of-mistral-7b-efficient-fine-tuning-for-medical-qa-fb3afaaa36e4)\n",
        "#Specifying training parameters(I have tried setting the various parameters;but for the safe run on my device;i have chosen this )\n",
        "training_arguments = TrainingArguments(\n",
        "    output_dir=new_model, #directory to save the model\n",
        "    per_device_train_batch_size=1, #batch size for training\n",
        "    per_device_eval_batch_size=1,#batch size for evaluation\n",
        "    gradient_accumulation_steps=2,#steps for accumulating gradients\n",
        "    optim=\"paged_adamw_32bit\", #optimizer for training\n",
        "    num_train_epochs=1,\n",
        "    evaluation_strategy=\"steps\", #step-wise evaluation\n",
        "    eval_steps=0.2,\n",
        "    logging_steps=1,\n",
        "    warmup_steps=10, #steps to warm up the learning rate\n",
        "    logging_strategy=\"steps\",\n",
        "    learning_rate=2e-4, #learning rate\n",
        "    fp16=False,\n",
        "    bf16=False,\n",
        "    group_by_length=True, #grouping the sequences by length\n",
        "    report_to=\"wandb\"  #report it to wan db\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50b88a0c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-12T20:56:09.305157Z",
          "iopub.status.busy": "2024-10-12T20:56:09.304895Z",
          "iopub.status.idle": "2024-10-12T20:56:10.155950Z",
          "shell.execute_reply": "2024-10-12T20:56:10.155127Z"
        },
        "papermill": {
          "duration": 0.865018,
          "end_time": "2024-10-12T20:56:10.158089",
          "exception": false,
          "start_time": "2024-10-12T20:56:09.293071",
          "status": "completed"
        },
        "tags": [],
        "id": "50b88a0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275,
          "referenced_widgets": [
            "76aa9bb827074b2591105355b3a6fa0d",
            "864da6e561c64c41bfa2a5e310f34bcf",
            "03723681b2c0464cb3df85c1d14d4388",
            "a443cc93a46e4c0183cfc7a09e171079",
            "e4839af8b7424833acfdb8aa4faa12f8",
            "62a4049d84984c18b7d22b8712cecb62",
            "87330848e2f04ccc8457cdfa96b2c060",
            "fc71ba1ceca34736917a46a4997874f9",
            "fe5879dfa5f3413b80dc6685ed705407",
            "4f7207b17187464bbfef7727d67342a0",
            "9c37143184314e6d81c62dc25c95cee8",
            "2d13f2a834154c709d313342ac14458b",
            "842654c77e954c70a6304b1338dddb75",
            "b5820dff1cbb4ee7a03d4052fc26a6ac",
            "a802591934414448ab799d1c97f2e827",
            "f647b0d0e50d488e90be3427ce2e1c69",
            "485fc9b2abbf4914864f8bc7449f0a66",
            "763ec666af2648eba8246b502eb04664",
            "a6f2dc09ad0d4398a0842391ee4f83aa",
            "4da1d50febc948dfb247b651068fb6ee",
            "7d9609abe12d4b2b89b5f946bb6309a0",
            "1190d11c5222418a81160486fd8e1cbb"
          ]
        },
        "outputId": "76ee4135-d084-44d7-a704-fadde064bb97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length, dataset_text_field. Will not be supported from version '0.13.0'.\n",
            "\n",
            "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/450 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "76aa9bb827074b2591105355b3a6fa0d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d13f2a834154c709d313342ac14458b"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# INSPIRED FROM THE SOURCE BLOG MENTIONED ABOVE (https://medium.com/@anicomanesh/unleashing-the-power-of-mistral-7b-efficient-fine-tuning-for-medical-qa-fb3afaaa36e4)\n",
        "#Initializing the trainer with the model, datasets, and settings\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset[\"train\"], #train data\n",
        "    eval_dataset=dataset[\"test\"], #test data\n",
        "    peft_config=peft_config,#LORA config\n",
        "    max_seq_length=512,  #max token sequence length\n",
        "    dataset_text_field=\"text\", #to use for training\n",
        "    tokenizer=tokenizer, #tokenizer\n",
        "    args=training_arguments,#training arguments\n",
        "    packing= False, #prevents from packing multiple sequences together\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TRaining the Model"
      ],
      "metadata": {
        "id": "RSpOHDnkUWR7"
      },
      "id": "RSpOHDnkUWR7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcb3f72c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-12T20:56:10.182875Z",
          "iopub.status.busy": "2024-10-12T20:56:10.182555Z",
          "iopub.status.idle": "2024-10-12T21:26:50.582002Z",
          "shell.execute_reply": "2024-10-12T21:26:50.580863Z"
        },
        "papermill": {
          "duration": 1840.414817,
          "end_time": "2024-10-12T21:26:50.584272",
          "exception": false,
          "start_time": "2024-10-12T20:56:10.169455",
          "status": "completed"
        },
        "tags": [],
        "id": "fcb3f72c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "outputId": "3f5dd239-3dba-4e39-b1b5-4b206027e4fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='225' max='225' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [225/225 09:57, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>4.512400</td>\n",
              "      <td>2.592734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>5.014600</td>\n",
              "      <td>2.542701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>135</td>\n",
              "      <td>3.927900</td>\n",
              "      <td>2.516154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>4.193900</td>\n",
              "      <td>2.486715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>5.696600</td>\n",
              "      <td>2.478566</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=225, training_loss=4.959238509072198, metrics={'train_runtime': 602.2847, 'train_samples_per_second': 0.747, 'train_steps_per_second': 0.374, 'total_flos': 4848569251356672.0, 'train_loss': 4.959238509072198, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "#model training process\n",
        "trainer.train()\n",
        "#These indicate a general downward trend in validation loss, which seems promising, though there’s some fluctuation in training loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b753ff96",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-12T21:26:50.609804Z",
          "iopub.status.busy": "2024-10-12T21:26:50.609453Z",
          "iopub.status.idle": "2024-10-12T21:26:52.248631Z",
          "shell.execute_reply": "2024-10-12T21:26:52.247698Z"
        },
        "papermill": {
          "duration": 1.654457,
          "end_time": "2024-10-12T21:26:52.250911",
          "exception": false,
          "start_time": "2024-10-12T21:26:50.596454",
          "status": "completed"
        },
        "tags": [],
        "id": "b753ff96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        },
        "outputId": "7f8a21f6-c76a-4c96-b395-2ffbcf34a90c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▅▃▁▁</td></tr><tr><td>eval/runtime</td><td>█▂▂▁▃</td></tr><tr><td>eval/samples_per_second</td><td>▁▇▆█▆</td></tr><tr><td>eval/steps_per_second</td><td>▁▇▆█▆</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇█</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▄▄▅▅▅▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>train/grad_norm</td><td>▁▂▁▁▁█▂▁▂▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▂▂▁▁▂▂▁▂</td></tr><tr><td>train/learning_rate</td><td>▂▄▇██▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▁▁</td></tr><tr><td>train/loss</td><td>▅▄▅▄▄▅▄▃▅▃▃▅▃▃▅▄▃▄▅▄▄▄▃▂▄▃█▅▅▄▃▄▂▅▃▁▃▅▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>2.47857</td></tr><tr><td>eval/runtime</td><td>24.0264</td></tr><tr><td>eval/samples_per_second</td><td>2.081</td></tr><tr><td>eval/steps_per_second</td><td>2.081</td></tr><tr><td>total_flos</td><td>4848569251356672.0</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>225</td></tr><tr><td>train/grad_norm</td><td>6.36811</td></tr><tr><td>train/learning_rate</td><td>0</td></tr><tr><td>train/loss</td><td>5.6966</td></tr><tr><td>train_loss</td><td>4.95924</td></tr><tr><td>train_runtime</td><td>602.2847</td></tr><tr><td>train_samples_per_second</td><td>0.747</td></tr><tr><td>train_steps_per_second</td><td>0.374</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">silver-serenity-18</strong> at: <a href='https://wandb.ai/hemu77-university-of-arizona/Fine-tune%20Mistral%207B%20Instruct%20on%20Medical%20Dataset/runs/vtts4gkx' target=\"_blank\">https://wandb.ai/hemu77-university-of-arizona/Fine-tune%20Mistral%207B%20Instruct%20on%20Medical%20Dataset/runs/vtts4gkx</a><br/> View project at: <a href='https://wandb.ai/hemu77-university-of-arizona/Fine-tune%20Mistral%207B%20Instruct%20on%20Medical%20Dataset' target=\"_blank\">https://wandb.ai/hemu77-university-of-arizona/Fine-tune%20Mistral%207B%20Instruct%20on%20Medical%20Dataset</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241102_222709-vtts4gkx/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#End the WandB run after training\n",
        "wandb.finish()\n",
        "model.config.use_cache = True #for model_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation Metrics"
      ],
      "metadata": {
        "id": "8rm2HgVkqw0q"
      },
      "id": "8rm2HgVkqw0q"
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing necessary libraries\n",
        "!pip install evaluate  #for bert score and rogue score  ;i want them to use as evaluation metric.\n",
        "!pip install rouge_score\n",
        "!pip install bert_score\n",
        "import numpy as np\n",
        "import evaluate"
      ],
      "metadata": {
        "id": "cAUidl27qpri",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ebb03d3-3938-4c26-96cd-2ef4824fe4e4"
      },
      "id": "cAUidl27qpri",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.10)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.0.0->evaluate) (0.2.0)\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.6)\n",
            "Requirement already satisfied: bert_score in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.5.0+cu121)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.2.2)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (4.46.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bert_score) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (4.66.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert_score) (3.8.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert_score) (24.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2024.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert_score) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.24.7)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.20.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (3.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2024.8.30)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert_score) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the metrics\n",
        "metric_bertscore = evaluate.load(\"bertscore\", lang=\"en\")\n",
        "metric_rouge = evaluate.load(\"rouge\")"
      ],
      "metadata": {
        "id": "qvBUt3YysIid"
      },
      "id": "qvBUt3YysIid",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zero-Shot Approach\n",
        "\n",
        "Here,we  evaluate the fine-tuned model on new test samples it hasn’t seen, without further  training on these specific samples.That's why it is a 'zero-shot'"
      ],
      "metadata": {
        "id": "tYcd_VcWwA14"
      },
      "id": "tYcd_VcWwA14"
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate model performance for zero-shot approach\n",
        "import pandas as pd\n",
        "\n",
        "def evaluate_zero_shot(model, tokenizer, test_samples, output_csv='evaluation_results.csv'):\n",
        "\n",
        "    results = []  # list to store results for each sample\n",
        "\n",
        "    # iterate over each sample in the test set\n",
        "    for sample in test_samples:\n",
        "        # extract the  fields from the current sample\n",
        "        description = sample['Description']\n",
        "        question = sample['Patient']\n",
        "        true_answer = sample['Doctor']\n",
        "\n",
        "        #  Creating  a conversation prompt based on the test data\n",
        "        prompt = f\"Description: {description}. Patient query: {question}. Respond as a medical expert: \"\n",
        "        input_ids = tokenizer.encode(prompt, return_tensors='pt').to(model.device)  # Encode prompt\n",
        "\n",
        "        # Generate a response from the model\n",
        "        with torch.no_grad():\n",
        "            predicted_answer = model.generate(input_ids, max_new_tokens=50)[0]  # Generate answer\n",
        "        predicted_answer_decoded = tokenizer.decode(predicted_answer, skip_special_tokens=True)  # Decode answer\n",
        "\n",
        "        # Calculate metrics for the generated response\n",
        "        bertscore_result = metric_bertscore.compute(predictions=[predicted_answer_decoded], references=[true_answer], lang=\"en\")\n",
        "        rouge_result = metric_rouge.compute(predictions=[predicted_answer_decoded], references=[true_answer])\n",
        "\n",
        "        # storing the evaluation results for each sample(proper order-professor-bulut told me to keep it in this order)\n",
        "        results.append({\n",
        "            \"prompt\": prompt,  #  input prompt\n",
        "            \"reference\": true_answer,  #  ground truth answer\n",
        "            \"prediction\": predicted_answer_decoded,  #  model's predicted answer\n",
        "            \"bert_precision\": bertscore_result['precision'][0],  # BERTScore precision\n",
        "            \"bert_recall\": bertscore_result['recall'][0],  # BERTScore recall\n",
        "            \"bert_f1\": bertscore_result['f1'][0],  # BERTScore F1 score\n",
        "            \"rouge1\": rouge_result[\"rouge1\"],  # ROUGE-1 score\n",
        "            \"rouge2\": rouge_result[\"rouge2\"],  # ROUGE-2 score\n",
        "            \"rougeL\": rouge_result[\"rougeL\"],  # ROUGE-L score\n",
        "            \"rougeLsum\": rouge_result[\"rougeLsum\"],  # ROUGE-L summation score\n",
        "        })\n",
        "\n",
        "    # Save hese results to a CSV file for easier readability and storage\n",
        "    pd.DataFrame(results).to_csv(output_csv, index=False)\n",
        "    print(\"Zero-Shot Evaluation Results saved to\", output_csv)\n"
      ],
      "metadata": {
        "id": "Avo3ANH4sXCA"
      },
      "id": "Avo3ANH4sXCA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# running the  evaluation on the Test Dataset\n",
        "evaluate_zero_shot(model,tokenizer, dataset[\"test\"])\n",
        "# model's responses share a good level of semantic relevance with the ground truth answers."
      ],
      "metadata": {
        "id": "Bc9wFFapeDgz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1887234-2444-4daf-9027-49e93e841c7d"
      },
      "id": "Bc9wFFapeDgz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zero-Shot Evaluation Results saved to evaluation_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Testing"
      ],
      "metadata": {
        "id": "QdZFM1aHm0AR"
      },
      "id": "QdZFM1aHm0AR"
    },
    {
      "cell_type": "code",
      "source": [
        "#my function for user to ask me (doc)-> a question\n",
        "#Read this approach (https://medium.com/@anicomanesh/unleashing-the-power-of-mistral-7b-efficient-fine-tuning-for-medical-qa-fb3afaaa36e4) and made my own changes referring to the site documentations\n",
        "def ask_doctor_hemanth(question):\n",
        "    # define the question template\n",
        "    prompt = f\"Hi, I'm Dr. Hemu. Patient query: {question}.\\nMy response as a medical expert: \"\n",
        "\n",
        "    # encode and prepare the input with the tokenized prompt\n",
        "    inputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True, max_length=512).to(\"cuda\")\n",
        "\n",
        "    # generate the answer using the model with adjusted parameters(referred from SOURCE:https://huggingface.co/docs/transformers/v4.46.0/en/main_classes/text_generation#transformers.GenerationMixin )\n",
        "    with torch.no_grad():  # No gradient needed for inference\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_length=512,  # Set higher max length for more detailed output\n",
        "            num_return_sequences=1,\n",
        "            num_beams=5,  # Use beam search for better quality\n",
        "            do_sample=True,  # Enable sampling for diversity\n",
        "            top_k=50,  # Limit sampling to top-k tokens\n",
        "            top_p=0.95,  # Using nucleus sampling\n",
        "            temperature=0.7  # Adjust temperature for more creative responses\n",
        "        )\n",
        "\n",
        "    # Decode the output and return it as a response\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # extract and format the answer for easy reading\n",
        "    if \"My response as a medical expert: \" in response:\n",
        "        answer = response.split(\"My response as a medical expert: \")[1]\n",
        "    else:\n",
        "        answer = response  # Fallback if format not found\n",
        "\n",
        "    # Remove unwanted phrases, including specific links/lines(i tested the code below using my prompts and got some common errors;so i included them in these)\n",
        "    unwanted_phrases = [\n",
        "        \"www.healthcaremagic.com\",\n",
        "        \"General & Family Physician\",\n",
        "        \"For more information consult a dermatologist online -->\",\n",
        "        \"Regards, Dr. Hemu,\"\n",
        "\n",
        "    ]\n",
        "\n",
        "    # Clean up the answer by removing unwanted phrases and duplicates\n",
        "    for phrase in unwanted_phrases:\n",
        "        answer = answer.replace(phrase, \"\")\n",
        "    # Additionally filter out any hospital/doctor-related phrases(i found some additional phrases after ;so i included them in these)\n",
        "    doctor_related_phrases = [\n",
        "        \"doctor\", \"hospital\", \"medical expert\", \"dermatologist\", \"consultation\", \"healthcare\", \"India\",\"Apollo Hospitals\",\"Hyderabad\",\"New Delhi\"\n",
        "    ]\n",
        "\n",
        "    for phrase in doctor_related_phrases:\n",
        "        answer = answer.replace(phrase, \"\")\n",
        "\n",
        "    # remove extra whitespace and lines, ensuring the unique content\n",
        "    answer_lines = list(set(answer.splitlines()))\n",
        "    cleaned_answer = \" \".join(line.strip() for line in answer_lines if line.strip())\n",
        "\n",
        "    # print final answer without unnecessary links or phrases\n",
        "    print(cleaned_answer)\n",
        "\n"
      ],
      "metadata": {
        "id": "kw211-hBsXHz"
      },
      "id": "kw211-hBsXHz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Medical Domain Questions(For Testing Purposes)"
      ],
      "metadata": {
        "id": "nNb36611nb9V"
      },
      "id": "nNb36611nb9V"
    },
    {
      "cell_type": "code",
      "source": [
        "ask_doctor_hemanth(\"I have bad acne.I am 16. How do I get rid of it?\")"
      ],
      "metadata": {
        "id": "P1Y5IZ50sXKf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5bc9a60-8eea-4a8d-f241-2d8efef0a350"
      },
      "id": "P1Y5IZ50sXKf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Wash your face with soap and water twice a day. 2. Apply a cream containing benzoyl peroxide once a day. 3. Apply a cream containing azelaic acid once a day. 4. Apply a cream containing clindamycin once a day. 5. Apply a cream containing erythromycin once a day. 6. Apply a cream containing tetracycline once a day. 7. Apply a cream containing minocycline once a day. 8. Apply a cream containing doxycycline once a day. 9. Apply a cream containing methyl salicylate once a day. 10. Apply a cream containing sulfacetamide once a day. 11. Apply a cream containing sodium sulfacetamide once a day. 12. Apply a cream containing erythromycin once a day. 13. Apply a cream containing tetracycline once a day. 14. Apply a cream containing minocycline once a day. 15. Apply a cream containing doxycycline once a day. 16. Apply a cream containing methyl salicylate once a day. 17. Apply a cream containing sulfacetamide once a day. 18. Apply a cream containing sodium sulfacetamide once a day. 19. Apply a cream containing erythromycin once a day. 20. Apply a cream containing tetracycline once a day. 21. Apply a cream containing minocycline once a day. 22. Apply a cream containing doxycycline once a day. 23. Apply a cream containing methyl salicylate once a day. 24. Apply a cream containing sulfacetamide once a day. 25. Apply a cream containing sodium sulfacetamide once a day. 26. Apply a cream containing erythromycin once a day. 27. Apply a cream containing tetracycline once a day. 28. Apply a cream containing minocycline once a day.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ask_doctor_hemanth(\"I have an alepecia in my beard.can you please help me with that?\")"
      ],
      "metadata": {
        "id": "jLch30D3sIl6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cf403a5-2cef-4670-f99d-bc28bc36d40c"
      },
      "id": "jLch30D3sIl6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi, I have gone through your query and understand your concern. Alopecia barbae is a type of alopecia in which there is hair loss in the beard area. The exact cause of alopecia barbae is not known, but it is thought to be due to an autoimmune disorder in which the body's immune system attacks its own hair follicles. The symptoms of alopecia barbae include patchy hair loss in the beard area, itching, and redness. The treatment of alopecia barbae includes topical corticosteroids, immunosuppressants, and anti-inflammatory drugs. In some cases, oral corticosteroids and immunosuppressants may also be used. It is important to consult a  for proper diagnosis and treatment. Hope I have answered your query. Let me know if I can assist you further.  Dermatologist.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ask_doctor_hemanth(\"I have a heavy bloating problem since 2 days;im 20.please,help me with that\")"
      ],
      "metadata": {
        "id": "X3f-q8AdVZ1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81faec9d-dac0-4912-ec60-44bcc5980ad9"
      },
      "id": "X3f-q8AdVZ1b",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi, Thanks for your query. I can understand your concern. Bloating can be due to many reasons. Some of the common causes are: 1. Overeating 2. Constipation 3. Hormonal imbalances 4. Gastrointestinal infections 5. Food allergies 6. Stress 7. Lack of sleep 8. Dehydration 9. Hormonal imbalances 10. Gastrointestinal infections 11. Food allergies 12. Stress 13. Lack of sleep 14. Dehydration 15. Hormonal imbalances 16. Gastrointestinal infections 17. Food allergies 18. Stress 19. Lack of sleep 20. Dehydration 21. Hormonal imbalances 22. Gastrointestinal infections 23. Food allergies 24. Stress 25. Lack of sleep 26. Dehydration 27. Hormonal imbalances 28. Gastrointestinal infections 29. Food allergies 30. Stress 31. Lack of sleep 32. Dehydration 33. Hormonal imbalances 34. Gastrointestinal infections 35. Food allergies 36. Stress 37. Lack of sleep 38. Dehydration 39. Hormonal imbalances 40. Gastrointestinal infections 41. Food allergies 42. Stress 43. Lack of sleep 44. Dehydration 45. Hormonal imbalances 46. Gastrointestinal infections 47. Food allergies 48. Stress 49. Lack of sleep 50. Dehydration 51. Hormonal imbalances 52. Gastrointestinal infections 53. Food allergies\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ask_doctor_hemanth(\"My ankle got twisted today; i can't able to walk;the swelling is huge;what to do?\")"
      ],
      "metadata": {
        "id": "xxJNkIE0VZ5G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "047ef935-9b4b-4e29-d49c-399c6fd847eb"
      },
      "id": "xxJNkIE0VZ5G",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Apply ice on the swollen area. 2. Elevate the leg. 3. Take painkillers like paracetamol or ibuprofen. 4. Don't apply heat on the swollen area. 5. Don't take any anti-inflammatory drugs like diclofenac or naproxen. 6. Don't take any blood thinners like warfarin. 7. Don't take any corticosteroids like prednisone. 8. Don't take any antihistamines like cetirizine or loratadine. 9. Don't take any antidepressants like fluoxetine or sertraline. 10. Don't take any antipsychotics like risperidone or olanzapine. 11. Don't take any anti-diabetic drugs like metformin or sitagliptin. 12. Don't take any anti-hypertensive drugs like amlodipine or losartan. 13. Don't take any anti-platelet drugs like aspirin or clopidogrel. 14. Don't take any anti-coagulant drugs like warfarin or enoxaparin. 15. Don't take any antibiotics like amoxicillin or ciprofloxacin. 16. Don't take any antiviral drugs like acyclovir or oseltamivir. 17. Don't take any antifungal drugs like ketoconazole or fluconazole. 18. Don't take any anti-parasitic drugs like albendazole or pyrimethamine. 19. Don't take any anti-inflammatory drugs like celecoxib or rofecoxib. 20. Don't take any anti-hypertensive drugs like amlodipine or losartan. 21. Don't take any anti-platelet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffc2db94",
      "metadata": {
        "papermill": {
          "duration": 0.014143,
          "end_time": "2024-10-12T21:37:56.613893",
          "exception": false,
          "start_time": "2024-10-12T21:37:56.599750",
          "status": "completed"
        },
        "tags": [],
        "id": "ffc2db94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c53ab9f-923c-43ab-d593-157df45284b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Exercise regularly. 2. Eat a healthy diet. 3. Get enough sleep. 4. Take care of your hygiene. 5. Take care of your mental health. 6. Take care of your physical health. 7. Take care of your emotional health. 8. Take care of your social health. 9. Take care of your spiritual health. 10. Take care of your academic health. 11. Take care of your professional health. 12. Take care of your personal health. 13. Take care of your family health. 14. Take care of your community health. 15. Take care of your national health. 16. Take care of your international health. 17. Take care of your global health. 18. Take care of your universal health. 19. Take care of your cosmic health. 20. Take care of your divine health. 21. Take care of your spiritual health. 22. Take care of your mental health. 23. Take care of your physical health. 24. Take care of your emotional health. 25. Take care of your academic health. 26. Take care of your professional health. 27. Take care of your personal health. 28. Take care of your family health. 29. Take care of your community health. 30. Take care of your national health. 31. Take care of your international health. 32. Take care of your global health. 33. Take care of your universal health. 34. Take care of your cosmic health. 35. Take care of your divine health. 36. Take care of your spiritual health. 37. Take care of your mental health. 38. Take care of your physical health. 39. Take care of your emotional health. 40. Take care of your academic health. 41. Take care of your professional health. 42. Take care of your personal health. 43. Take care\n"
          ]
        }
      ],
      "source": [
        "ask_doctor_hemanth(\"I just came to another country for my master's.I feel so low and my stress and anxiety levels are increasing;im 20;what to do?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now,lets move on to testing the base model without fine tuning ->its in **base_model_evaluation.ipynb**(Gpu crashed;it made me move those code cells to another ipynb files in order to complete my project)"
      ],
      "metadata": {
        "id": "-hbHyZdqsG4t"
      },
      "id": "-hbHyZdqsG4t"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34012a3b",
      "metadata": {
        "papermill": {
          "duration": 0.013844,
          "end_time": "2024-10-12T21:37:56.641534",
          "exception": false,
          "start_time": "2024-10-12T21:37:56.627690",
          "status": "completed"
        },
        "tags": [],
        "id": "34012a3b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "isSourceIdPinned": true,
          "modelId": 1902,
          "modelInstanceId": 3900,
          "sourceId": 5112,
          "sourceType": "modelInstanceVersion"
        },
        {
          "modelId": 121027,
          "modelInstanceId": 100936,
          "sourceId": 120005,
          "sourceType": "modelInstanceVersion"
        }
      ],
      "dockerImageVersionId": 30559,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 2789.73813,
      "end_time": "2024-10-12T21:37:59.977026",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-10-12T20:51:30.238896",
      "version": "2.4.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2452632335924d479f7d94c01ae3c2d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ebb528d60c194d1f8444e58c78559c6c",
              "IPY_MODEL_542b6c5e8d794f85b61f0f8c98a74c63",
              "IPY_MODEL_9060eb9f3df94e1a9b368dcdc6391044"
            ],
            "layout": "IPY_MODEL_6915c7b31f7141739651b31d3a474f93"
          }
        },
        "ebb528d60c194d1f8444e58c78559c6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_deb8db8a5a864057ad35931c8f113096",
            "placeholder": "​",
            "style": "IPY_MODEL_34905186e8f34f10a9e6ecced5d46472",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "542b6c5e8d794f85b61f0f8c98a74c63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f931ee02737494089a20241b4c88fcc",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88cac15e6a734fdc9ef6afd5792900ef",
            "value": 2
          }
        },
        "9060eb9f3df94e1a9b368dcdc6391044": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e98ee422e83f4e2fa9794f5cdd056c3a",
            "placeholder": "​",
            "style": "IPY_MODEL_c2b1af3ecdde4c62877372e0d48d13f1",
            "value": " 2/2 [01:14&lt;00:00, 34.82s/it]"
          }
        },
        "6915c7b31f7141739651b31d3a474f93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "deb8db8a5a864057ad35931c8f113096": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34905186e8f34f10a9e6ecced5d46472": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f931ee02737494089a20241b4c88fcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88cac15e6a734fdc9ef6afd5792900ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e98ee422e83f4e2fa9794f5cdd056c3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2b1af3ecdde4c62877372e0d48d13f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76aa9bb827074b2591105355b3a6fa0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_864da6e561c64c41bfa2a5e310f34bcf",
              "IPY_MODEL_03723681b2c0464cb3df85c1d14d4388",
              "IPY_MODEL_a443cc93a46e4c0183cfc7a09e171079"
            ],
            "layout": "IPY_MODEL_e4839af8b7424833acfdb8aa4faa12f8"
          }
        },
        "864da6e561c64c41bfa2a5e310f34bcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62a4049d84984c18b7d22b8712cecb62",
            "placeholder": "​",
            "style": "IPY_MODEL_87330848e2f04ccc8457cdfa96b2c060",
            "value": "Map: 100%"
          }
        },
        "03723681b2c0464cb3df85c1d14d4388": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc71ba1ceca34736917a46a4997874f9",
            "max": 450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe5879dfa5f3413b80dc6685ed705407",
            "value": 450
          }
        },
        "a443cc93a46e4c0183cfc7a09e171079": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f7207b17187464bbfef7727d67342a0",
            "placeholder": "​",
            "style": "IPY_MODEL_9c37143184314e6d81c62dc25c95cee8",
            "value": " 450/450 [00:00&lt;00:00, 1321.48 examples/s]"
          }
        },
        "e4839af8b7424833acfdb8aa4faa12f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62a4049d84984c18b7d22b8712cecb62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87330848e2f04ccc8457cdfa96b2c060": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc71ba1ceca34736917a46a4997874f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe5879dfa5f3413b80dc6685ed705407": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f7207b17187464bbfef7727d67342a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c37143184314e6d81c62dc25c95cee8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d13f2a834154c709d313342ac14458b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_842654c77e954c70a6304b1338dddb75",
              "IPY_MODEL_b5820dff1cbb4ee7a03d4052fc26a6ac",
              "IPY_MODEL_a802591934414448ab799d1c97f2e827"
            ],
            "layout": "IPY_MODEL_f647b0d0e50d488e90be3427ce2e1c69"
          }
        },
        "842654c77e954c70a6304b1338dddb75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_485fc9b2abbf4914864f8bc7449f0a66",
            "placeholder": "​",
            "style": "IPY_MODEL_763ec666af2648eba8246b502eb04664",
            "value": "Map: 100%"
          }
        },
        "b5820dff1cbb4ee7a03d4052fc26a6ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6f2dc09ad0d4398a0842391ee4f83aa",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4da1d50febc948dfb247b651068fb6ee",
            "value": 50
          }
        },
        "a802591934414448ab799d1c97f2e827": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d9609abe12d4b2b89b5f946bb6309a0",
            "placeholder": "​",
            "style": "IPY_MODEL_1190d11c5222418a81160486fd8e1cbb",
            "value": " 50/50 [00:00&lt;00:00, 770.59 examples/s]"
          }
        },
        "f647b0d0e50d488e90be3427ce2e1c69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "485fc9b2abbf4914864f8bc7449f0a66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "763ec666af2648eba8246b502eb04664": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6f2dc09ad0d4398a0842391ee4f83aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4da1d50febc948dfb247b651068fb6ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d9609abe12d4b2b89b5f946bb6309a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1190d11c5222418a81160486fd8e1cbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}